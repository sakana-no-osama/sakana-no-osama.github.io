# -*- coding: utf-8 -*-
"""
Final21 (accuracy-first):
 - Use only current team_*.html as sources (fresh-only).
 - Strict row parsing, full/half width digits, OG exclusion, name-cell detection.
 - Dedup by (name, team) taking MAX goals.
 - Prefer team name from H1/H2/Title if present; fallback to filename.
 - Archive all previous Final outputs safely into _old_backup/<timestamp>.
Outputs:
  index_kngsafe_final21.html, team_totals_final21.html, team_players_final21.html, ranking_log_vFinal21.json
"""

import os, re, json, shutil, datetime, html

BASE = "/sdcard/Download/sakana-no-osama.github.io"
OUT_ALL   = os.path.join(BASE, "index_kngsafe_final21.html")
OUT_TTOT  = os.path.join(BASE, "team_totals_final21.html")
OUT_TPLAY = os.path.join(BASE, "team_players_final21.html")
LOGFILE   = os.path.join(BASE, "ranking_log_vFinal21.json")

# ---------- utils ----------
def now_tag():
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def esc(s: str) -> str:
    return html.escape(s.strip())

def read_text(p):
    with open(p, "r", encoding="utf-8", errors="ignore") as f:
        return f.read()

def archive_old():
    pats = [
        r"index_kngsafe_final\d+\.html",
        r"team_totals_final\d+\.html",
        r"team_players_final\d+\.html",
        r"ranking_log_vFinal\d+\.json",
    ]
    moved = []
    dest = None
    for f in os.listdir(BASE):
        if any(re.fullmatch(p, f) for p in pats):
            if dest is None:
                dest = os.path.join(BASE, "_old_backup", now_tag())
                os.makedirs(dest, exist_ok=True)
            shutil.move(os.path.join(BASE, f), os.path.join(dest, f))
            moved.append(f)
    return {"moved": moved, "dest": dest}

def guess_team_from_filename(fname):
    core = re.sub(r"^team_", "", os.path.basename(fname))
    core = re.sub(r"\.html?$", "", core, flags=re.I)
    core = core.replace("_", " ")
    return core.strip()

# å…¨è§’â†’åŠè§’æ•°å­—
ZEN2HAN = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")
def han_digits(s):
    return s.translate(ZEN2HAN)

# ---------- tolerant parser (rule-based strict) ----------
KANJI = r"ä¸€-é¾¥ã€…ã€†"
KATA  = r"ã‚¡-ãƒ´ãƒ¼ï½¦-ï¾Ÿ"
HIRA  = r"ã-ã‚–"
ALPH  = r"A-Za-z"
NAME_RE = re.compile(rf"[{KANJI}{KATA}{HIRA}{ALPH}0-9ï½¥ãƒ»\.\-ã€€ \(\)]+")
DIGITS_TAIL = re.compile(r"(\d+)\s*$")
OG_RE = re.compile(r"(?:\bOG\b|ã‚ªã‚¦ãƒ³|è‡ªæ®ºç‚¹)", re.I)
PK_PARENS = re.compile(r"ï¼ˆ\s*PK\s*ï¼‰|\(.*?PK.*?\)", re.I)
HEADER_LIKE = {"é¸æ‰‹", "é¸æ‰‹å", "æ°å", "name"}

TD_RE = re.compile(r"<t[dh][^>]*>(.*?)</t[dh]>", re.I|re.S)
TR_RE = re.compile(r"<tr[^>]*>(.*?)</tr>", re.I|re.S)

def strip_html(s):
    s = re.sub(r"<[^>]+>", "", s)
    s = s.replace("&nbsp;", " ")
    s = s.replace("\u3000", " ")
    s = s.strip()
    s = han_digits(s)
    return s

def team_name_from_head(html_text, fallback):
    # Prefer H1/H2, then <title>
    m = re.search(r"<h[12][^>]*>(.*?)</h[12]>", html_text, re.I|re.S)
    if m:
        t = strip_html(m.group(1))
        if 2 <= len(t) <= 60:
            return t
    m = re.search(r"<title[^>]*>(.*?)</title>", html_text, re.I|re.S)
    if m:
        t = strip_html(m.group(1))
        # ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œãƒãƒ¼ãƒ ã€ã€ŒU-15ã€ç­‰ãŒæ··ã–ã‚‹å ´åˆã¯çŸ­ã„åã«ãƒˆãƒªãƒ 
        t = re.sub(r"(?i)u-?15.*", "", t).strip()
        if 2 <= len(t) <= 60:
            return t
    return fallback

def parse_team_file(path, drops_log):
    raw = read_text(path)
    team = team_name_from_head(raw, guess_team_from_filename(path))

    rows = TR_RE.findall(raw)
    players = []
    for tr in rows:
        cells = [strip_html(x) for x in TD_RE.findall(tr)]
        if len(cells) < 2:
            continue

        # æœ«å°¾æ•´æ•°ï¼ˆå¾—ç‚¹ï¼‰
        goals = None
        for c in reversed(cells):
            m = DIGITS_TAIL.search(c)
            if m:
                try:
                    goals = int(m.group(1))
                    break
                except:
                    pass
        if goals is None:
            continue

        joined = " ".join(cells)
        if OG_RE.search(joined):
            # å®Œå…¨é™¤å¤–
            continue

        # åå‰ã‚»ãƒ«ã‚’æ¢ã™ï¼ˆæ•°å­—ã‚»ãƒ«ä»¥å¤–ã§æœ€åˆã®NAME_REãƒ’ãƒƒãƒˆï¼‰
        name = None
        for c in cells:
            if DIGITS_TAIL.search(c):
                continue
            if c in HEADER_LIKE:
                continue
            m = NAME_RE.search(c)
            if m:
                name = m.group(0).strip()
                break
        if not name:
            drops_log.append({"team": team, "row": cells, "reason": "no-name-cell"})
            continue

        # æ³¨è¨˜é™¤å»
        name = PK_PARENS.sub("", name)
        name = re.sub(r"\s+", " ", name).strip()
        if not name or name in HEADER_LIKE:
            drops_log.append({"team": team, "row": cells, "reason": "header-like"})
            continue

        # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ¥µç«¯ãªå¾—ç‚¹ã¯ç–‘ç¾©æ‰±ã„ã§æ¡ç”¨ã€ãƒ­ã‚°ã«è¨˜éŒ²ï¼‰
        if goals > 50:
            drops_log.append({"team": team, "row": cells, "reason": f"suspect-high-goals({goals})"})

        players.append((name, goals))

    return team, players

def collect_sources():
    srcs = []
    for fn in sorted(os.listdir(BASE)):
        if fn.startswith("team_") and fn.lower().endswith(".html"):
            srcs.append(os.path.join(BASE, fn))
    return srcs

def build_rankings(src_paths):
    per_pair = {}  # (name, team) -> max goals
    drops = []
    teams_seen = set()

    for p in src_paths:
        team, plist = parse_team_file(p, drops)
        teams_seen.add(team)
        for name, g in plist:
            key = (name, team)
            if g > per_pair.get(key, 0):
                per_pair[key] = g

    # people list
    people = [(n, t, g) for (n, t), g in per_pair.items()]
    people.sort(key=lambda x: (-x[2], x[0], x[1]))

    # team totals & team players
    team_tot = {}
    team_players = {}
    for n, t, g in people:
        team_tot[t] = team_tot.get(t, 0) + g
        team_players.setdefault(t, []).append((n, g))
    for t in team_players:
        team_players[t].sort(key=lambda x: (-x[1], x[0]))

    team_rank = sorted(team_tot.items(), key=lambda x: (-x[1], x[0]))
    return people, team_rank, team_players, sorted(teams_seen), drops

# ---------- HTML ----------
CSS = """
<style>
body{font-family:sans-serif;margin:18px}
h1{font-size:20px;margin:0 0 8px}
h2{font-size:16px;margin:18px 0 6px}
small{color:#555}
table{border-collapse:collapse;width:100%;max-width:980px}
th,td{border:1px solid #ccc;padding:6px 8px;font-size:13px}
th{background:#f6f6f6}
.rank{width:56px;text-align:right}
.name{width:36%}
.team{width:42%}
.goals{width:70px;text-align:right}
.section{margin:22px 0 12px}
</style>
"""

def write_overall(people):
    lines = []
    lines.append("<html><head><meta charset='utf-8'><title>U-15 çµ±åˆå¾—ç‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Final21)</title>"+CSS+"</head><body>")
    lines.append("<h1>U-15 é–¢æ±1éƒ¨ãƒ»2éƒ¨ çµ±åˆå¾—ç‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆFinal21ï¼‰</h1>")
    lines.append("<small>ç¾å­˜ team_*.html ã®ã¿ã‚’å…¥åŠ›ã€‚OG/ã‚ªã‚¦ãƒ³/è‡ªæ®ºç‚¹ã¯é™¤å¤–ã€‚åŒå§“åŒåã¯åˆ¥äººæ‰±ã„ã€‚é‡è¤‡è¡Œã¯(åå‰,ãƒãƒ¼ãƒ )ã®æœ€å¤§å¾—ç‚¹ã‚’æ¡ç”¨ã€‚</small>")
    lines.append("<div class='section'></div>")
    lines.append("<table><tr><th class='rank'>é †ä½</th><th class='name'>é¸æ‰‹å</th><th class='team'>ãƒãƒ¼ãƒ </th><th class='goals'>å¾—ç‚¹</th></tr>")
    prev, rank = None, 0
    for i,(n,t,g) in enumerate(people,1):
        if g != prev:
            rank = i
            prev = g
        lines.append(f"<tr><td class='rank'>{rank}</td><td class='name'>{esc(n)}</td><td class='team'>{esc(t)}</td><td class='goals'>{g}</td></tr>")
    lines.append("</table>")
    lines.append(f"<p><small>å‡ºåŠ›ä»¶æ•°ï¼š{len(people)} å</small></p>")
    lines.append("</body></html>")
    open(OUT_ALL,"w",encoding="utf-8").write("\n".join(lines))

def write_team_totals(team_rank):
    lines = []
    lines.append("<html><head><meta charset='utf-8'><title>ãƒãƒ¼ãƒ åˆ¥ åˆè¨ˆå¾—ç‚¹ (Final21)</title>"+CSS+"</head><body>")
    lines.append("<h1>ãƒãƒ¼ãƒ åˆ¥ åˆè¨ˆå¾—ç‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆFinal21ï¼‰</h1>")
    lines.append("<table><tr><th class='rank'>é †ä½</th><th class='team'>ãƒãƒ¼ãƒ </th><th class='goals'>åˆè¨ˆ</th></tr>")
    prev, rank = None, 0
    for i,(t,s) in enumerate(team_rank,1):
        if s != prev:
            rank = i
            prev = s
        lines.append(f"<tr><td class='rank'>{rank}</td><td class='team'>{esc(t)}</td><td class='goals'>{s}</td></tr>")
    lines.append("</table></body></html>")
    open(OUT_TTOT,"w",encoding="utf-8").write("\n".join(lines))

def write_team_players(team_players):
    lines = []
    lines.append("<html><head><meta charset='utf-8'><title>ãƒãƒ¼ãƒ åˆ¥ é¸æ‰‹ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Final21)</title>"+CSS+"</head><body>")
    lines.append("<h1>ãƒãƒ¼ãƒ åˆ¥ é¸æ‰‹å¾—ç‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆFinal21ï¼‰</h1>")
    for t in sorted(team_players.keys()):
        lines.append(f"<h2>{esc(t)}</h2>")
        lines.append("<table><tr><th class='rank'>é †ä½</th><th class='name'>é¸æ‰‹å</th><th class='goals'>å¾—ç‚¹</th></tr>")
        prev, rank = None, 0
        for i,(n,g) in enumerate(team_players[t],1):
            if g != prev:
                rank = i
                prev = g
            lines.append(f"<tr><td class='rank'>{rank}</td><td class='name'>{esc(n)}</td><td class='goals'>{g}</td></tr>")
        lines.append("</table><div class='section'></div>")
    lines.append("</body></html>")
    open(OUT_TPLAY,"w",encoding="utf-8").write("\n".join(lines))

# ---------- main ----------
def main():
    archived = archive_old()
    srcs = collect_sources()
    if not srcs:
        print("âš ï¸ team_*.html ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
        return

    people, team_rank, team_players, teams_seen, drops = build_rankings(srcs)

    write_overall(people)
    write_team_totals(team_rank)
    write_team_players(team_players)

    log = {
        "timestamp": now_tag(),
        "sources": [os.path.basename(p) for p in srcs],
        "teams_detected": teams_seen,
        "people_count": len(people),
        "team_count": len(team_rank),
        "drops": drops[:200],        # ãƒ­ã‚°è‚¥å¤§é˜²æ­¢ã§å…ˆé ­200ä»¶
        "archived": archived
    }
    open(LOGFILE,"w",encoding="utf-8").write(json.dumps(log, ensure_ascii=False, indent=2))

    print("âœ… å‡ºåŠ›å®Œäº†ï¼š")
    print("  -", OUT_ALL)
    print("  -", OUT_TTOT)
    print("  -", OUT_TPLAY)
    print("ğŸ—‚ï¸ ãƒ­ã‚°ï¼š", LOGFILE)
    if archived.get("moved"):
        print("ğŸ—„ï¸ æ—§æˆæœç‰©ã‚’é€€é¿ï¼š", archived["dest"])

if __name__ == "__main__":
    main()

